# -*- coding: utf-8 -*-
"""FaceRecognitionV4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dqsoV9nKlZKpmaK04hYMUvq4af8Y_v93
"""

pip install face-recognition

from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

def take_photo(filename='imgTest.jpg', quality=0.8):
  
  js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});

      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      // Resize the output to fit the video element.
      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);

      // Wait for Capture to be clicked.
      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('imgTest/jpeg', quality);
    }
    ''')
  display(js)
  data = eval_js('takePhoto({})'.format(quality))
  binary = b64decode(data.split(',')[1])
  with open(filename, 'wb') as f:
    f.write(binary)
  return filename

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from matplotlib import pyplot as plt
import cv2
import dlib
import os
import face_recognition

def prepare_training_data():

  attendees_images = os.listdir('/content/drive/My Drive/training-data_fr')
  labels = ["leonardo", "obama", "tom", "bill", "lebron", "sujay"]
  encodings = []

  for attendee_image in attendees_images:

    img = face_recognition.load_image_file('/content/drive/My Drive/training-data_fr/' + attendee_image)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.imshow(img)
    plt.show()
    facePos = face_recognition.face_locations(img)[0]
    encodeImg = face_recognition.face_encodings(img)[0]
    cv2.rectangle(img, (facePos[3], facePos[0]), (facePos[1], facePos[2]), (255, 0, 255), 2)
    encodings.append(encodeImg)

  return labels, encodings

def predict(test_image_path, labels, encodings):

  test_image = face_recognition.load_image_file(test_image_path)
  test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)
  facePosTest = face_recognition.face_locations(test_image)[0]
  encodeTest = face_recognition.face_encodings(test_image)[0]
  cv2.rectangle(test_image, (facePosTest[3], facePosTest[0]), (facePosTest[1], facePosTest[2]), (255, 0, 255), 2)
  i = 0
  test_result = "unknown"

  for encoding in encodings:

    results = face_recognition.compare_faces([encoding], encodeTest)
    face_dis = face_recognition.face_distance([encoding], encodeTest) 
    print(results[0]) 
    print(i)
    if bool(results[0]) is True:
      print("abc")       
      test_result = labels[i] + ' ' + str(round(face_dis[0], 2))
    i = i + 1
    # print(results, faceDis)

  cv2.putText(test_image, f'{test_result}', (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)
  plt.imshow(test_image)
  plt.show()



#cv2.imshow('Registered Subject', imgEncode)
#cv2.imshow('Test Img', imgTest)
#cv2.waitKey(0)

from IPython.display import Image
try:
  filename = take_photo()
  print('Saved to {}'.format(filename))
  
  # Show the image which was just taken.
  # display(Image(filename))

  labels, encodings = prepare_training_data()
  predict('/content/imgTest.jpg', labels, encodings)
  
except Exception as err:
  # Errors will be thrown if the user does not have a webcam or if they do not
  # grant the page permission to access it.
  print(str(err))
